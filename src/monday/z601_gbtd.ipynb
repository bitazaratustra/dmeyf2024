{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Vd-Rfyik62j"
   },
   "source": [
    "# Gradient Boosting Desicion Tree\n",
    "\n",
    "En las clases anteriores, observamos cómo las mejoras en los algoritmos y las optimizaciones pueden generar avances significativos en la ganancia. Ya hemos logrado un progreso considerable con los modelos de Random Forest. Hoy, daremos un paso aún más grande al explorar los modelos que actualmente están obteniendo los mejores resultados en este tipo de dominios.\n",
    "\n",
    "Antes que nada, carguemos el entorno de trabajo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vhhu79HVkwb5",
    "outputId": "716a5fdc-6920-4f17-ce88-5a275032f5f1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib==3.7.1\n",
      "  Downloading matplotlib-3.7.1.tar.gz (38.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from matplotlib==3.7.1) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from matplotlib==3.7.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from matplotlib==3.7.1) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from matplotlib==3.7.1) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from matplotlib==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from matplotlib==3.7.1) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from matplotlib==3.7.1) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from matplotlib==3.7.1) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from matplotlib==3.7.1) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.7.1) (1.16.0)\n",
      "Building wheels for collected packages: matplotlib\n",
      "  Building wheel for matplotlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for matplotlib: filename=matplotlib-3.7.1-cp312-cp312-linux_x86_64.whl size=11048416 sha256=7d84b607dbae676dc63357558ea9002a2a8713378c69aa772d121d4a552b38c9\n",
      "  Stored in directory: /home/baldasseroniluisesteban/.cache/pip/wheels/1c/06/fa/3453aac11411fac092c1bdfe52815f2f6969a42700d977e62f\n",
      "Successfully built matplotlib\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.9.2\n",
      "    Uninstalling matplotlib-3.9.2:\n",
      "      Successfully uninstalled matplotlib-3.9.2\n",
      "Successfully installed matplotlib-3.7.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting optuna==3.6.1\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from optuna==3.6.1) (1.13.3)\n",
      "Requirement already satisfied: colorlog in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from optuna==3.6.1) (6.8.2)\n",
      "Requirement already satisfied: numpy in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from optuna==3.6.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from optuna==3.6.1) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from optuna==3.6.1) (2.0.36)\n",
      "Requirement already satisfied: tqdm in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from optuna==3.6.1) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from optuna==3.6.1) (6.0.2)\n",
      "Requirement already satisfied: Mako in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna==3.6.1) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna==3.6.1) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from sqlalchemy>=1.3.0->optuna==3.6.1) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna==3.6.1) (3.0.2)\n",
      "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "Installing collected packages: optuna\n",
      "  Attempting uninstall: optuna\n",
      "    Found existing installation: optuna 4.0.0\n",
      "    Uninstalling optuna-4.0.0:\n",
      "      Successfully uninstalled optuna-4.0.0\n",
      "Successfully installed optuna-3.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install scikit-learn==1.3.2\n",
    "#%pip install seaborn==0.13.1\n",
    "#%pip install numpy==1.26.4\n",
    "%pip install matplotlib==3.7.1\n",
    "#%pip install pandas==2.1.4\n",
    "#%pip install lightgbm==4.4.0\n",
    "%pip install optuna==3.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[dataframe] in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (2024.10.0)\n",
      "Requirement already satisfied: click>=8.1 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from dask[dataframe]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from dask[dataframe]) (3.1.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from dask[dataframe]) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from dask[dataframe]) (24.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from dask[dataframe]) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from dask[dataframe]) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: pandas>=2.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from dask[dataframe]) (2.2.3)\n",
      "Collecting dask-expr<1.2,>=1.1 (from dask[dataframe])\n",
      "  Downloading dask_expr-1.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
      "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading dask_expr-1.1.18-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading dask_expr-1.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (17.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
      "Requirement already satisfied: locket in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.16.0)\n",
      "Downloading dask_expr-1.1.16-py3-none-any.whl (243 kB)\n",
      "Installing collected packages: dask-expr\n",
      "Successfully installed dask-expr-1.1.16\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install \"dask[dataframe]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Cj-rL6xHlA2u"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baldasseroniluisesteban/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "\n",
    "from time import time\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jGKjoN1lRho",
    "outputId": "a568ae03-670f-4d96-d367-c29bb0c2d6d9"
   },
   "outputs": [],
   "source": [
    "base_path = '/home/baldasseroniluisesteban/buckets/b1/'\n",
    "dataset_path = base_path + 'datasets/'\n",
    "dataset_file = 'competencia_02_lags.csv.gz'\n",
    "\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "mes_train_inicio = 201901\n",
    "mes_train_final = 202104\n",
    "mes_test = 202106\n",
    "\n",
    "# agregue sus semillas\n",
    "semillas = [127,181,13]\n",
    "\n",
    "\n",
    "data = pd.read_csv(dataset_path + dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['clase_ternaria_lag_1', 'clase_ternaria_lag_2', 'clase_ternaria_lag_3',\n",
    "                   'clase_ternaria_lag_6', 'clase_ternaria_lag_12'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TrH9f1L5Umd"
   },
   "source": [
    "Vamos a asignar pesos a las clases. En unos minutos explicaremos las razones detrás de esta decisión. Mientras tanto, pueden aprovechar el código para ajustar el peso de la clase **BAJA+2** según lo deseen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlYeDIBQP3-s"
   },
   "outputs": [],
   "source": [
    "data['clase_peso'] = 1.0\n",
    "\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzLIRVs850-I"
   },
   "source": [
    "Además, como se mencionó en la clase pasada, comenzaremos a experimentar con nuevas clases para ajustar el modelo. En particular, sumaremos la clase **BAJA+1**, que es estructuralmente muy similar a **BAJA+2**, para aumentar los casos positivos. Luego, compararemos los resultados obtenidos con los de la clase con la que hemos estado trabajando hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KV1meQ5cZ_Sl"
   },
   "outputs": [],
   "source": [
    "data['clase_binaria1'] = 0\n",
    "data['clase_binaria2'] = 0\n",
    "data['clase_binaria1'] = np.where(data['clase_ternaria'] == 'BAJA+2', 1, 0)\n",
    "data['clase_binaria2'] = np.where(data['clase_ternaria'] == 'CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AYJG0r16dW9"
   },
   "source": [
    "Y trabajaremos como es habitual en las últimas clases, con **Febrero** para entrenar y **Abril** para medir, con el fin de realizar *backtesting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDyeXHAuCKuT"
   },
   "outputs": [],
   "source": [
    "train_data = data[(mes_train_inicio <= data['foto_mes']) & (data['foto_mes'] <= mes_train_final)]\n",
    "test_data = data[data['foto_mes'] == mes_test]\n",
    "\n",
    "X_train = train_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_train_binaria1 = train_data['clase_binaria1']\n",
    "y_train_binaria2 = train_data['clase_binaria2']\n",
    "w_train = train_data['clase_peso']\n",
    "\n",
    "X_test = test_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "y_test_binaria1 = test_data['clase_binaria1']\n",
    "y_test_class = test_data['clase_ternaria']\n",
    "w_test = test_data['clase_peso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scpnp1HJ6wfO"
   },
   "source": [
    "Y preparamos el *dataset* para poder usar el **rf** de una clase anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cqbDiI4x2OD"
   },
   "outputs": [],
   "source": [
    "# imp_mean = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "# Xif = imp_mean.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k31eSe5zlTEk"
   },
   "source": [
    "Comenzaremos explicando el funcionamiento del protagonista de esta clase: **LightGBM**. Primero, partiremos con una revisión de cómo funciona el algoritmo en el que se basa, **XGBoost**. Para una introducción completa, puedes consultar este\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/tutorials/model.html.\n",
    "\n",
    "Aunque en la cátedra no somos grandes seguidores de Josh Starmer y su canal *StatQuest*, reconozco que sus series sobre *Gradient Boosting* y *XGBoost* son excelentes recursos. Aquí te dejamos los enlaces a esas dos series que realmente valen la pena:\n",
    "\n",
    "[Serie Gradient Boosting](https://www.youtube.com/watch?v=3CC4N4z3GJc&list=PLblh5JKOoLUJjeXUvUE0maghNuY2_5fY6)\n",
    "\n",
    "[Serie XGBoost](https://www.youtube.com/watch?v=OtD8wVaFm6E&list=PLblh5JKOoLULU0irPgs1SnKO6wqVjKUsQ)\n",
    "\n",
    "Finalmente, analizaremos las diferencias clave que ofrece **LightGBM** frente a XGBoost. Puedes explorar más sobre ello en este https://lightgbm.readthedocs.io/en/stable/Features.html.\n",
    "\n",
    "No olvides tener a mano la [documentación de LightGBM](https://lightgbm.readthedocs.io/)y la [lista completa de sus parámetros](https://lightgbm.readthedocs.io/en/latest/Parameters.html).\n",
    "\n",
    "Este es un algoritmo muy usado en el mercado, recomiendo dedicarle el tiempo necesario para aprenderlo bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ-3AgzL9ude"
   },
   "source": [
    "Vamos a utilizar el algoritmo directamente, sin pasar por *scikit-learn*. Sin embargo, si algún alumno lo prefiere, puede optar por usar el *wrapper* de sklearn para este caso.\n",
    "\n",
    "Para evaluar la calidad del modelo, crearemos nuestra propia función de evaluación que calcule la ganancia. La razón de incluir los pesos es precisamente para poder implementar esta función de evaluación de manera adecuada. Al combinar las clases *BAJA+1* y *BAJA+2* en una sola, necesitamos una forma de diferenciarlas, y es aquí donde entra en juego el *weight*. Este parámetro nos permitirá distinguir entre ambas clases al momento de evaluarlas dentro del algoritmo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FvDUXeatl66"
   },
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True\n",
    "\n",
    "# Parámetros del modelos.\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'gan_eval',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qte_kOcU-7i3"
   },
   "source": [
    "LGBM necesita su propio tipo de Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dnWsRWgPnRr"
   },
   "outputs": [],
   "source": [
    "train_data1 = lgb.Dataset(X_train, label=y_train_binaria1, weight=w_train)\n",
    "train_data2 = lgb.Dataset(X_train, label=y_train_binaria2, weight=w_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GSEwNi3_IxN"
   },
   "source": [
    "A continuación, compararemos las dos clases. Utilizaremos para medir la calidad de las clases (y de los parámetros), la función **cv** que viene *out-of-the-box*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibXn1tiLNT6J"
   },
   "outputs": [],
   "source": [
    "# cv_results1 = lgb.cv(\n",
    "#     params,\n",
    "#     train_data1,\n",
    "#     num_boost_round=150,\n",
    "#     feval=lgb_gan_eval,\n",
    "#     nfold=5,\n",
    "#     seed=semillas[0]\n",
    "# )\n",
    "\n",
    "# cv_results2 = lgb.cv(\n",
    "#     params,\n",
    "#     train_data2,\n",
    "#     num_boost_round=150,\n",
    "#     feval=lgb_gan_eval,\n",
    "#     nfold=5,\n",
    "#     seed=semillas[0]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePRPrDL8_odf"
   },
   "source": [
    "Y vizualizamos los resultados de ambas ejecuciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "cOoWx9sbhx5h",
    "outputId": "83228183-9c35-4f2e-c05e-333e06994aa5"
   },
   "outputs": [],
   "source": [
    "# df_ganancias = pd.DataFrame({\n",
    "#     'binaria1': cv_results1['valid gan_eval-mean'],\n",
    "#     'binaria2': cv_results2['valid gan_eval-mean'],\n",
    "#     'Iteracion': range(1, len(cv_results1['valid gan_eval-mean']) + 1)\n",
    "# })\n",
    "\n",
    "# # Normalizamos la ganancias\n",
    "# df_ganancias['binaria1'] = df_ganancias['binaria1']*5\n",
    "# df_ganancias['binaria2'] = df_ganancias['binaria2']*5\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(x='Iteracion', y='binaria1', data=df_ganancias, label='binaria 1')\n",
    "# sns.lineplot(x='Iteracion', y='binaria2', data=df_ganancias, label='binaria 2')\n",
    "# plt.title('Comparación de las Ganancias de las 2 clases binarias')\n",
    "# plt.xlabel('Iteración')\n",
    "# plt.ylabel('Ganancia')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N96lUJOLDqLH"
   },
   "source": [
    "Se observa una ligera mejora al combinar las clases en modelos sencillos. Dado que cada pequeña mejora es importante, continuaremos utilizando esta estrategia.\n",
    "\n",
    "A continuación, procederemos a optimizar **LightGBM** utilizando la librería **Optuna**. Cabe destacar que las optimizaciones que realizaremos son básicas y están diseñadas para ejecutarse en pocos minutos. Será su responsabilidad ampliar tanto el rango de búsqueda como el tiempo de optimización para obtener un modelo más competitivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYMEnNFbkSoQ",
    "outputId": "908a675a-9d67-4563-fd3f-809bf6530e3c"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    num_leaves = trial.suggest_int('num_leaves', 100, 500)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.2)\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 1000)\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.3, 1.0)\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.3, 1.0)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 100)\n",
    "    bagging_freq = trial.suggest_int('bagging_freq', 1, 300)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'max_depth': max_depth,\n",
    "        'bagging_freq': bagging_freq,\n",
    "        'seed': semillas[0],\n",
    "        'verbose': -1,\n",
    "        'early_stopping' :30,\n",
    "    }\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                              label=y_train_binaria2, # eligir la clase\n",
    "                              weight=w_train)\n",
    "\n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=50,\n",
    "        feval=lgb_gan_eval,\n",
    "        stratified=True,\n",
    "        nfold=5,\n",
    "        seed=semillas[0]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos cual es la mejor iteración del modelo\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan * 5\n",
    "\n",
    "\n",
    "storage_name = \"sqlite:///\" + dataset_path + \"optimization_lgbm_lags.db\"\n",
    "study_name = \"exp_201_lgbm_lags\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMrT22K0u9JF",
    "outputId": "45edfde2-67ec-4a73-ba46-5fe887eaf4bd"
   },
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=10) # subir subir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ia2vN07FEasX"
   },
   "source": [
    "Analizamos los resultados as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "fH4ybQgYx7Xf",
    "outputId": "cb86dcbc-35e3-451b-c135-f89bb5a3fcbb"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "vOfm5DXAx8Rj",
    "outputId": "999067e6-4ede-4ce5-d545-f1e5bf9d419c"
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0Z-r8QYEsNN"
   },
   "source": [
    "El **learning rate** es un parámetro que tiene que ir acompañado por más árboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "0U6CfznSx-gG",
    "outputId": "64f6a497-b5cc-473e-c041-8bc64b8179bf"
   },
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRqPgCD6yB_q",
    "outputId": "a9731037-508f-436e-d948-a7983a6daa0b"
   },
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGHGdGcQ3m00",
    "outputId": "b24cbb7d-5877-4101-fdd9-0488ce2f1e4c"
   },
   "outputs": [],
   "source": [
    "plot_contour(study, params=['num_leaves','min_data_in_leaf'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjgD6raVE6am"
   },
   "source": [
    "Y finalmente tomamos el mejor modelo y lo entrenamos con la totalidad de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRfHvHeqguVj",
    "outputId": "18676b80-f678-4a1f-e5ec-0f0c7994c8ca"
   },
   "outputs": [],
   "source": [
    "X_train.foto_mes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwyUriQksZAM",
    "outputId": "55cd304a-7112-42df-e3a5-80129fa6e7c6"
   },
   "outputs": [],
   "source": [
    "best_iter = study.best_trial.user_attrs[\"best_iter\"]\n",
    "print(f\"Mejor cantidad de árboles para el mejor model {best_iter}\")\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': study.best_trial.params['num_leaves'],\n",
    "    'learning_rate': study.best_trial.params['learning_rate'],\n",
    "    'min_data_in_leaf': study.best_trial.params['min_data_in_leaf'],\n",
    "    'feature_fraction': study.best_trial.params['feature_fraction'],\n",
    "    'bagging_fraction': study.best_trial.params['bagging_fraction'],\n",
    "    'seed': semillas[0],\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                          label=y_train_binaria2,\n",
    "                          weight=w_train)\n",
    "\n",
    "model = lgb.train(params,\n",
    "                  train_data,\n",
    "                  num_boost_round=best_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOyqa5mbFySM"
   },
   "source": [
    "Observamos la variables más importantes para el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUejb7eutd0i",
    "outputId": "d6db3c61-ceb9-40c8-e913-bbdefdcfb4ac"
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(model, figsize=(10, 20))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkTH9daXF5tp"
   },
   "source": [
    "Y si queremos tener las variables más importantes en forma de *Dataframe*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7ZObpkHtnUl",
    "outputId": "e723a650-165b-4859-af68-1c7941d259c2"
   },
   "outputs": [],
   "source": [
    "importances = model.feature_importance()\n",
    "feature_names = X_train.columns.tolist()\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "importance_df[importance_df['importance'] > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwvqxqc_GB-C"
   },
   "source": [
    "Para guardar el modelo para poder utilizarlo más adelante, no es necesario guardarlo como *pickle*, la librería nos permite guardarlo en formato texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0lWWxwHhs2gp",
    "outputId": "5f17ff0d-b811-48ca-835a-931c93bf93ad"
   },
   "outputs": [],
   "source": [
    "model.save_model(modelos_path + 'lgb_first.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHIUeAdsGOWv"
   },
   "source": [
    "Y recuperar el mismo desde ese formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H12h5wP2s645"
   },
   "outputs": [],
   "source": [
    "model = lgb.Booster(model_file=modelos_path + 'lgb_first.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_-xspdWGSwT"
   },
   "source": [
    "Para realizar nuestra habitual comparación de modelos, partiremos desde el mejor que obtuvimos hasta ahora, el **rf**. Para este fin cargaremos el *binario* que ajustamos un par de clases atrás:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J31X1oeRwxbt"
   },
   "outputs": [],
   "source": [
    "filename_rf_1000 = modelos_path + 'exp_206_random_forest_model_1000.sav'\n",
    "model_rf_1000 = pickle.load(open(filename_rf_1000, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28TQpPlIGi6a"
   },
   "source": [
    "Y sobre ambos modelos obtenemos la predicción de **Abril**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjjLshxzopUU",
    "outputId": "684e9bf7-e1b0-4586-ae29-89782f5fd1b4"
   },
   "outputs": [],
   "source": [
    "model_rf_1000.fit(X_train, y_train_binaria2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kL9dBAv4xWz2",
    "outputId": "f3d03d34-60a5-4821-888b-b4b034127ecf"
   },
   "outputs": [],
   "source": [
    "y_pred_rf = model_rf_1000.predict_proba(Xif)\n",
    "y_pred_rf = y_pred_rf[:,1] # adaptamos la salida para que sea homogénea con el LGBM\n",
    "\n",
    "y_pred_lgm = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtivqQ2OGvxC"
   },
   "source": [
    "Finalmente medimos las ganancias de ambos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSvtslh-uMcK",
    "outputId": "7eb591be-28ec-4b87-adec-2cb4215c90fa"
   },
   "outputs": [],
   "source": [
    "def ganancia_prob(y_pred, y_true, prop = 1):\n",
    "  ganancia = np.where(y_true == 1, ganancia_acierto, 0) - np.where(y_true == 0, costo_estimulo, 0)\n",
    "  return ganancia[y_pred >= 0.025].sum() / prop\n",
    "\n",
    "print(\"Ganancia RF:\", ganancia_prob(y_pred_rf, y_test_binaria1))\n",
    "print(\"Ganancia LGBM:\", ganancia_prob(y_pred_lgm, y_test_binaria1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KdAKkYQGz7K"
   },
   "source": [
    "Vemos un nuevo salto, tan alto como el del árbol al rf. Será simplemente suerte? veamos que sucede sobre múltiples **LDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-EFxmQtzcs0"
   },
   "outputs": [],
   "source": [
    "sss_futuro = StratifiedShuffleSplit(n_splits=50,\n",
    "                             test_size=0.3,\n",
    "                             random_state=semillas[0])\n",
    "modelos = {\"rf\":y_pred_rf, \"lgbm\":y_pred_lgm}\n",
    "rows = []\n",
    "for private_index, public_index in sss_futuro.split(X_test, y_test_binaria1):\n",
    "  row = {}\n",
    "  for name, y_pred in modelos.items():\n",
    "    row[name + \"_public\"] = ganancia_prob(y_pred[public_index], y_test_binaria1.iloc[public_index], 0.3)\n",
    "    row[name + \"_private\"] = ganancia_prob(y_pred[private_index], y_test_binaria1.iloc[private_index], 0.7)\n",
    "  rows.append(row)\n",
    "df_lb = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76Adb5Q6zhG7"
   },
   "outputs": [],
   "source": [
    "df_lb_long = df_lb.reset_index()\n",
    "df_lb_long = df_lb_long.melt(id_vars=['index'], var_name='model_type', value_name='ganancia')\n",
    "df_lb_long[['modelo', 'tipo']] = df_lb_long['model_type'].str.split('_', expand=True)\n",
    "df_lb_long = df_lb_long[['ganancia', 'tipo', 'modelo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTG3w3UXzjQK",
    "outputId": "feb2fe49-a054-4607-8572-300d723deabb"
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df_lb_long, col=\"tipo\", row=\"modelo\", aspect=2)\n",
    "g.map(sns.histplot, \"ganancia\", kde=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsPshEZVHTw_"
   },
   "source": [
    "Otra vez se observa la superioridad del **LGBM**. Veamos que hubiera pasado si elegíamos el mejor del público"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQ9CARjWzeIm",
    "outputId": "718834b1-f5f0-4f8b-a094-e0ad0e3fdfa2"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['best_public'] = df_lb.filter(regex='_public').idxmax(axis=1)\n",
    "df['best_private'] = df_lb.filter(regex='_private').idxmax(axis=1)\n",
    "\n",
    "pd.crosstab(df['best_public'], df['best_private'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7rwLi7IHi3-"
   },
   "source": [
    "Observamos que en 50 **LDBs** solo en un público ganó un **rf**, sin embargo en el 100% de los casos, en el privado ganó un **lgbm**. Asombroso.\n",
    "\n",
    "Pero el alumno atento, vio que para la selección del mejor modelo no se utilizó ningún punto de corte. Podrá pasar que el mejor punto de corte en entrenamiento, no sea el mejor para un mes en el futuro?\n",
    "\n",
    "Veamos para esto la curva de ganancia en función de los puntos de corte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85csWJ6p5huj"
   },
   "outputs": [],
   "source": [
    "ganancia = np.where(y_test_binaria1 == 1, ganancia_acierto, 0) - np.where(y_test_binaria1 == 0, costo_estimulo, 0)\n",
    "\n",
    "idx = np.argsort(y_pred_lgm)[::-1]\n",
    "\n",
    "ganancia = ganancia[idx]\n",
    "y_pred_lgm = y_pred_lgm[idx]\n",
    "\n",
    "ganancia_cum = np.cumsum(ganancia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yULvAtz964Ek",
    "outputId": "2860417b-4dad-46b1-d83d-27f9446cfb74"
   },
   "outputs": [],
   "source": [
    "piso_envios = 4000\n",
    "techo_envios = 20000\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_pred_lgm[piso_envios:techo_envios], ganancia_cum[piso_envios:techo_envios], label='Ganancia LGBM')\n",
    "plt.title('Curva de Ganancia')\n",
    "plt.xlabel('Predicción de probabilidad')\n",
    "plt.ylabel('Ganancia')\n",
    "plt.axvline(x=0.025, color='g', linestyle='--', label='Punto de corte a 0.025')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrRvBfUEIM0Y"
   },
   "source": [
    "Vaya! realmente nuestro teórico mejor punto de corte no es el que mayor ganancia genera. Es hora de cambiar el enfoque.\n",
    "\n",
    "En vez de mirar el punto de corte, empezaremos a pensar en cuál es la cantidad máxima de clientes que se deben estimular. Si cambiamos a esto, veremos que el gráfico anterior se ve así"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgLC9YI15xr8",
    "outputId": "52b76763-a8af-4b2e-9e60-29875b6d17a9"
   },
   "outputs": [],
   "source": [
    "piso_envios = 4000\n",
    "techo_envios = 20000\n",
    "\n",
    "ganancia_max = ganancia_cum.max()\n",
    "gan_max_idx = np.where(ganancia_cum == ganancia_max)[0][0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(piso_envios, len(ganancia_cum[piso_envios:techo_envios]) + piso_envios), ganancia_cum[piso_envios:techo_envios], label='Ganancia LGBM')\n",
    "plt.axvline(x=gan_max_idx, color='g', linestyle='--', label=f'Punto de corte a la ganancia máxima {gan_max_idx}')\n",
    "plt.axhline(y=ganancia_max, color='r', linestyle='--', label=f'Ganancia máxima {ganancia_max}')\n",
    "plt.title('Curva de Ganancia')\n",
    "plt.xlabel('Clientes')\n",
    "plt.ylabel('Ganancia')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAxBMAYzI2yW"
   },
   "source": [
    "Lo que significa que la cantidad de envíos que maximiza la ganancia es 12601.\n",
    "\n",
    "Claro, estamos haciendo trampa. No nunca vamos a contar con datos del futuro para determinar este punto de corte...  o sí?\n",
    "\n",
    "En nuestro caso, si contamos con una pequeña ventana de datos del futuro, el **leaderboard público**.\n",
    "\n",
    "Realicemos un análisis para determinar si el leaderboard puede ayudarnos a identificar el punto de corte óptimo que maximice la ganancia en el conjunto de datos privado.\n",
    "\n",
    "En la siguiente función cambie la semilla para evaluar como cambia los **leaderboards**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDSE3m2c716w",
    "outputId": "3ea5a684-bae6-437a-e6c1-4b07749781d4"
   },
   "outputs": [],
   "source": [
    "def analisis_1(semilla):\n",
    "  df_cut_point = pd.DataFrame({'ganancia': ganancia, 'y_pred_lgm': y_pred_lgm})\n",
    "\n",
    "  private_idx, public_idx = train_test_split(df_cut_point.index, test_size=0.3, random_state=semilla, stratify=y_test_binaria1)\n",
    "\n",
    "  df_cut_point['public'] = 0.0\n",
    "  df_cut_point['private'] = 0.0\n",
    "  df_cut_point.loc[private_idx, 'private'] = ganancia[private_idx] / 0.7\n",
    "  df_cut_point.loc[public_idx, 'public'] = ganancia[public_idx] / 0.3\n",
    "\n",
    "  df_cut_point['nro_envios'] = df_cut_point.reset_index().index\n",
    "\n",
    "  df_cut_point['public_cum'] = df_cut_point['public'].cumsum()\n",
    "  df_cut_point['private_cum'] = df_cut_point['private'].cumsum()\n",
    "\n",
    "  plt.figure(figsize=(10, 6))\n",
    "  plt.plot(df_cut_point['nro_envios'][4000:20000], df_cut_point['public_cum'][4000:20000], label='Ganancia Pública Acumulada')\n",
    "  plt.plot(df_cut_point['nro_envios'][4000:20000], df_cut_point['private_cum'][4000:20000], label='Ganancia Privada Acumulada')\n",
    "\n",
    "  max_public_cum = df_cut_point['public_cum'][4000:20000].max()\n",
    "  max_public_idx = df_cut_point['public_cum'][4000:20000].idxmax()\n",
    "  plt.axvline(x=max_public_idx, color='g', linestyle='--', label=f'Máximo Ganancia Pública en {max_public_idx}')\n",
    "\n",
    "  max_private_cum = df_cut_point['private_cum'][4000:20000].max()\n",
    "  max_private_idx = df_cut_point['private_cum'][4000:20000].idxmax()\n",
    "  plt.axvline(x=max_private_idx, color='r', linestyle='--', label=f'Máximo Ganancia Privada en {max_private_idx}')\n",
    "\n",
    "  plt.title('Curva de Ganancia Pública y Privada')\n",
    "  plt.xlabel('Número de envíos')\n",
    "  plt.ylabel('Ganancia Acumulada')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "analisis_1(semillas[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9Q-wD6tKYUm"
   },
   "source": [
    "Qué conclusión sacó?\n",
    "\n",
    "Hay un nuevo pero. Sería fabuloso poder contar con la curva de todo el **leaderboard público**, pero no es posible. Hay una cantidad finita de envíos. El siguiente análisis de back testing es más exacto.\n",
    "\n",
    "**JUEGUE**\n",
    "- Ponga en False el parámetro **private**\n",
    "- Cambie la semilla\n",
    "- Determine la cantidad de casos que va a enviar al leaderboard público. Recuerde que no tiene más de 20 por día.\n",
    "- Determine la cantidad optima mirando la gráfica\n",
    "- Ponga el True poder visualizar la curva del **leaderboard privado**\n",
    "- Evalue que tan bien le acerto.\n",
    "- Repita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pcWJmHPlchV5",
    "outputId": "c642e92b-6fe4-4944-b905-db798d1e3607"
   },
   "outputs": [],
   "source": [
    "def analisis_2(semilla, desde, paso, cantidad, private = False):\n",
    "\n",
    "  df_cut_point = pd.DataFrame({'ganancia': ganancia, 'y_pred_lgm': y_pred_lgm})\n",
    "  df_cut_point['nro_envios'] = df_cut_point.reset_index().index\n",
    "\n",
    "  plt.figure(figsize=(10, 6))\n",
    "\n",
    "  private_idx, public_idx = train_test_split(df_cut_point.index, test_size=0.3, random_state=semilla, stratify=y_test_binaria1)\n",
    "\n",
    "  df_cut_point['public'] = 0.0\n",
    "  df_cut_point.loc[public_idx, 'public'] = ganancia[public_idx] / 0.3\n",
    "  df_cut_point['public_cum'] = df_cut_point['public'].cumsum()\n",
    "\n",
    "  maximo_paso = desde + paso*cantidad\n",
    "  plt.plot(df_cut_point['nro_envios'][list(range(desde, maximo_paso + 1, paso))], df_cut_point['public_cum'][list(range(desde, maximo_paso + 1, paso))], label='Ganancia Pública Acumulada')\n",
    "  max_public_cum = df_cut_point['public_cum'][list(range(desde, maximo_paso + 1, paso))].max()\n",
    "  max_public_idx = df_cut_point['public_cum'][list(range(desde, maximo_paso + 1, paso))].idxmax()\n",
    "  plt.axvline(x=max_public_idx, color='g', linestyle='--', label=f'Máximo Ganancia Pública en {max_public_idx}')\n",
    "\n",
    "  if private:\n",
    "    df_cut_point['private'] = 0.0\n",
    "    df_cut_point.loc[private_idx, 'private'] = ganancia[private_idx] / 0.7\n",
    "    df_cut_point['private_cum'] = df_cut_point['private'].cumsum()\n",
    "    plt.plot(df_cut_point['nro_envios'][4000:20000], df_cut_point['private_cum'][4000:20000], label='Ganancia Privada Acumulada')\n",
    "    max_private_cum = df_cut_point['private_cum'][4000:20000].max()\n",
    "    max_private_idx = df_cut_point['private_cum'][4000:20000].idxmax()\n",
    "    plt.axvline(x=max_private_idx, color='r', linestyle='--', label=f'Máximo Ganancia Privada en {max_private_idx}')\n",
    "\n",
    "  plt.title('Curva de Ganancia Pública y Privada')\n",
    "  plt.xlabel('Número de envíos')\n",
    "  plt.ylabel('Ganancia Acumulada')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "analisis_2(semillas[1], 4000, 500, 10, private=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Aat38kYztkq"
   },
   "source": [
    "## Tarea:\n",
    "\n",
    "1. **Generar Dataset**  \n",
    "   - Utilice las técnicas de *feature engineering* vistas en las clases anteriores para generar un nuevo conjunto de datos.\n",
    "   \n",
    "2. **Optimización de LightGBM (LGBM)**  \n",
    "   - Ajuste el modelo de LightGBM utilizando una mayor cantidad de árboles y realice una exploración más exhaustiva de los hiperparámetros para mejorar su rendimiento.\n",
    "   \n",
    "3. **Incluir Nuevos Parámetros en la Optimización**  \n",
    "   - Revise la documentación de los parámetros de LightGBM. Evalúe la inclusión de otros parámetros en el proceso de optimización, y ajuste el modelo con estos nuevos parámetros.\n",
    "   \n",
    "4. **Selección del Mejor Modelo**  \n",
    "   - Entre los cinco mejores modelos obtenidos en cada optimización, seleccione el que considere más adecuado para la competencia en Kaggle.\n",
    "   - Documente las pruebas que realizó para seleccionar el mejor modelo. Justifique su decisión con métricas relevantes y análisis comparativos.\n",
    "5. Escriba y comparta por **Zulip** una función que envíe prepare el dataset que es necesario enviar a **kaggle** con los N clientes con mayor probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yF69AmnZxqRZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = lgb.Booster(model_file=modelos_path + 'lgb_first.txt')\n",
    "\n",
    "mes_test = 202106\n",
    "X_test = data[data['foto_mes'] == mes_test].drop(columns=['clase_ternaria', 'clase_binaria1', 'clase_binaria2', 'clase_peso'])\n",
    "\n",
    "pred_v101 = model.predict(X_test)\n",
    "\n",
    "threshold = 0.025\n",
    "\n",
    "X_test['Predicted'] = np.where(pred_v101 > threshold, 1, 0)\n",
    "\n",
    "df = X_test[['numero_de_cliente', 'Predicted']]\n",
    "\n",
    "df.to_csv('modelo_v001.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YaZSSNOx7vFj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
